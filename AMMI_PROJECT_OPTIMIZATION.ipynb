{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMMI_PROJECT_OPTIMIZATION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhG1ATIpbH4PS3nzt0SRZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eecheonwu/ammi_ml-proj/blob/main/AMMI_PROJECT_OPTIMIZATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoBlesps65AV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nR_n90ST24Bk",
        "outputId": "79519eef-9a0d-4137-9946-dcd10c36703d"
      },
      "source": [
        "! pip install -U pandas==1.0.3\n",
        "! pip install -U trains>=0.16.2\n",
        "! pip install -U optuna==2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==1.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/71/8f53bdbcbc67c912b888b40def255767e475402e9df64050019149b1a943/pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.3) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.3) (1.15.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "Successfully installed pandas-1.0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b0/9a6313c78bca92abfacc08a2ad8b27bfe845256f615786ee2b6452ae1978/optuna-2.0.0.tar.gz (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 4.3MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 6.7MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.9MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/03/5d15a78ca92ac2bf09f466c54c48bb92979dfe19add2dfed415133ba9792/cmaes-0.6.1-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/10/0b39be7ff1adb8888fe87c8628c071dec5ac282ac1c2312221f5feb09215/colorlog-4.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (1.3.19)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna==2.0.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna==2.0.0) (2.8.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==2.0.0) (2.4.7)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a1/004f04ba411a8002b02aadb089fd6868116c12ddc9f6d576175e89d07587/stevedore-3.2.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==2.0.0) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/a3/d439f338aa90edd5ad9096cd56564b44882182150e92148eb14ceb7488ba/pbr-5.5.0-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==2.0.0) (0.7.2)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/94/0f4f16cff4977188d715a95ea3f90f054b7eb73b05afaf51431a3d77b992/cmd2-1.3.11-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==2.0.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna==2.0.0) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna==2.0.0) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna==2.0.0) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna==2.0.0) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna==2.0.0) (20.2.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna==2.0.0) (3.2.0)\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.0.0-cp36-none-any.whl size=312967 sha256=3cc437639841ffc505b3fcd9e0a84ee2d07ca9204a1bb0c3cc291448d0f7b236\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/c9/03/c45484454bf657ffed0ed6af153bd3d213928df115eb2a56eb\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=1952c7c5cdae237cf8fd713067395750326b7009a4c167c8f8e1ffe73ef91a43\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: python-editor, Mako, alembic, pbr, stevedore, pyperclip, colorama, cmd2, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.3 cliff-3.4.0 cmaes-0.6.1 cmd2-1.3.11 colorama-0.4.4 colorlog-4.4.0 optuna-2.0.0 pbr-5.5.0 pyperclip-1.8.1 python-editor-1.0.4 stevedore-3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-gFpHYA4Ako"
      },
      "source": [
        "from trains.automation import UniformParameterRange, UniformIntegerParameterRange\n",
        "from trains.automation import HyperParameterOptimizer\n",
        "from trains.automation.optuna import OptimizerOptuna\n",
        "\n",
        "from trains import Task\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "F9xYsR-W4FkR",
        "outputId": "6d2834f9-b5bd-4422-fb57-9412234b67d8"
      },
      "source": [
        "task = Task.init(project_name='Hyperparameter Optimization',\n",
        "                 task_name='Hyperparameter Optimization for AMMI Project',\n",
        "                 task_type=Task.TaskTypes.optimizer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINS Task: created new task id=8b0343c7e5f6438fb647362d3e50d02f\n",
            "2020-10-18 21:49:43,485 - trains.Task - INFO - No repository found, storing script code instead\n",
            "TRAINS results page: https://demoapp.trains.allegro.ai/projects/e26fd5f55d224d24b4f2f22a9899e262/experiments/8b0343c7e5f6438fb647362d3e50d02f/output/log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HS4Ko6Q4KqQ"
      },
      "source": [
        "TEMPLATE_TASK_ID = '8b0343c7e5f6438fb647362d3e50d02f'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "8TZ-WR5k4OJU",
        "outputId": "8a883c75-89ab-475e-ce9f-f0ddba908feb"
      },
      "source": [
        "optimizer = HyperParameterOptimizer(\n",
        "    base_task_id=TEMPLATE_TASK_ID,  # This is the experiment we want to optimize\n",
        "    # here we define the hyper-parameters to optimize\n",
        "    hyper_parameters=[\n",
        "        UniformIntegerParameterRange('n_epochs', min_value=5, max_value=30, step_size=1),\n",
        "        UniformIntegerParameterRange('lr_step', min_value=0, max_value=8, step_size=1),\n",
        "        UniformParameterRange('n_weight', min_value=0, max_value=0.5, step_size=0.05),\n",
        "        UniformParameterRange('n_lr', min_value=0.0005, max_value=0.01, step_size=0.0005),\n",
        "        UniformParameterRange('n_gamma', min_value=0, max_value=0.3, step_size=0.05),\n",
        "    ],,\n",
        "           \n",
        "    ],\n",
        "    # setting the objective metric we want to maximize/inimize\n",
        "    objective_metric_title='losses',\n",
        "    objective_metric_series='loss',\n",
        "    #objective_metric_sign='min',  # maximize or minimize the objective metric\n",
        "\n",
        "    # setting optimizer - trains supports GridSearch, RandomSearch, OptimizerBOHB and OptimizerOptuna\n",
        "    optimizer_class=OptimizerOptuna,\n",
        "    \n",
        "    # Configuring optimization parameters\n",
        "    execution_queue='default',  # queue to schedule the experiments for execution\n",
        "    max_number_of_concurrent_tasks=3,  # number of concurrent experiments\n",
        "    optimization_time_limit=30.,  # set the time limit for the optimization process\n",
        "    compute_time_limit=120,  # set the compute time limit (sum of execution time on all machines)\n",
        "    total_max_jobs=10,  # set the maximum number of experiments for the optimization. \n",
        "                        # Converted to total number of iteration for OptimizerBOHB\n",
        "    min_iteration_per_job=15000,  # minimum number of iterations per experiment, till early stopping\n",
        "    max_iteration_per_job=150000,  # maximum number of iterations per experiment\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 22:12:54,726 - trains.automation.optimization - WARNING - Could not find requested hyper-parameters ['n_epochs', 'n_gamma', 'n_lr', 'n_momentum', 'n_step_size', 'n_weight_decay'] on base task 8b0343c7e5f6438fb647362d3e50d02f\n",
            "2020-10-18 22:12:55,017 - trains.automation.optimization - WARNING - Could not find requested metric ('', '') report on base task 8b0343c7e5f6438fb647362d3e50d02f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gy5qYfii4Ul7"
      },
      "source": [
        "optimizer.set_report_period(1)  # setting the time gap between two consecutive reports\n",
        "optimizer.start()  \n",
        "optimizer.wait()  # wait until process is done\n",
        "optimizer.stop()  # make sure background optimization stopped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQavyzBi4X4c"
      },
      "source": [
        "# optimization is completed, print the top performing experiments id\n",
        "k = 3\n",
        "top_exp = optimizer.get_top_experiments(top_k=k)\n",
        "print('Top {} experiments are:'.format(k))\n",
        "for n, t in enumerate(top_exp, 1):\n",
        "    print('Rank {}: task id={} |result={}'\n",
        "          .format(n, t.id, t.get_last_scalar_metrics()['loss']['loss']['last']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE2NpeoNts5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}