{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip setuptools wheel\n",
    "! pip install --index https://pypi.voxel51.com fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install detecto\n",
    "! pip install torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import detecto\n",
    "from detecto.core import Model\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained  Model for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<detecto.core.Model object at 0x7f446c290c18> :Model ready\n"
     ]
    }
   ],
   "source": [
    "# Run the model on GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "labels= [\"House\", \"Car\", \"Ongoing Construction\", \"Built-up area\", \"Water Storage\", \"Bus\", \"Truck\", \"Train Track\"]\n",
    "# Load a pre-trained Faster R-CNN model\n",
    "model = Model.load('/home/emmanuel/ammi_ml-proj/model.pth', labels)\n",
    "print(model, \":Model ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |██████████████████████████████████████████████████████████████████████████████████████████| 9/9 [87.2ms elapsed, 0s remaining, 103.2 samples/s]     \n"
     ]
    }
   ],
   "source": [
    "name = \"object-detection_Project\"\n",
    "dataset_dir = \"/home/emmanuel/ammi_ml-proj/dataset/\"\n",
    "\n",
    "# Create the dataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, fo.types.VOCDetectionDataset, name=name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Dataset Uniqueness ( please change port on each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.compute_uniqueness(dataset)\n",
    "dups_view = dataset.sort_by(\"uniqueness\")\n",
    "# Launch the App\n",
    "session = fo.launch_app(view=dups_view, port=7080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select rondomly test images to use and make predictions on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_view = dataset.take(9, seed=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from detecto.utils import read_image\n",
    "from torchvision.transforms import functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |██████████████████████████████████████████████████████████████████████████████████████████| 9/9 [35.8s elapsed, 0s remaining, 0.3 samples/s]       \n",
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(predictions_view):\n",
    "        # Load image\n",
    "        image = Image.open(sample.filepath)\n",
    "        image = func.to_tensor(image).to(device)\n",
    "        c, h, w = image.shape\n",
    "\n",
    "        # Perform inference\n",
    "        image = read_image(sample.filepath)\n",
    "\n",
    "\n",
    "        labels, boxes, scores = model.predict([image])[0]\n",
    "        \n",
    "        scores = scores.detach().numpy()\n",
    "        boxes = boxes.detach().numpy()\n",
    "\n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            x1, y1, x2, y2 = box\n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(fo.Detection(\n",
    "                label=label,\n",
    "                bounding_box=rel_box,\n",
    "                confidence=score\n",
    "            ))\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample[\"model\"] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select predictions greater than 0.55 confidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only keep detections with confidence > 0.55\n",
    "high_conf_view = predictions_view.filter_detections(\"model\", F(\"confidence\") > 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '5fc62ac227871c3a7c5b6744',\n",
      "    '_id': '5fc62ac227871c3a7c5b6744',\n",
      "    'attributes': BaseDict({}),\n",
      "    'label': 'House',\n",
      "    'bounding_box': BaseList([\n",
      "        0.1947205596499973,\n",
      "        0.40360496662281176,\n",
      "        0.13765078120761448,\n",
      "        0.13736399897822626,\n",
      "    ]),\n",
      "    'mask': None,\n",
      "    'confidence': 0.9840937256813049,\n",
      "    'index': None,\n",
      "    '_cls': 'Detection',\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "sample = high_conf_view.first()\n",
    "print(sample.model.detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:        object-detection_Project\n",
      "Media type:     image\n",
      "Num samples:    9\n",
      "Tags:           []\n",
      "Sample fields:\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    model:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "Pipeline stages:\n",
      "    1. Take(size=9, seed=45)\n"
     ]
    }
   ],
   "source": [
    "print(predictions_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View result to compare predictions and ground truth (please change port on each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for emmanuel: \n",
      "App launched\n"
     ]
    }
   ],
   "source": [
    "! sudo sysctl kernel.unprivileged_userns_clone=1\n",
    "\n",
    "# Open the dataset in the App\n",
    "session = fo.launch_app(dataset=dataset, port=7050) \n",
    "# Load view containing the subset of samples for which we added predictions\n",
    "session.view = predictions_view  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
